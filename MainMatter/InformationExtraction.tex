%===================================================================================
% Chapter: Extracción de Información
%===================================================================================
\chapter{Extracción de Información}\label{chapter:information_extraction}
\addcontentsline{toc}{chapter}{Extracción de Información}

\section{Extracción de Entidades}

Una entidad nombrada es una palabra o frase que identifica un objeto de un conjunto de objetos que tienen atributos similares. Ejemplos de esto son las personas, las organizaciones, drogas, nombres de enfermedades dentro del dominio m\'edico, entre otros. \textbf{Reconocimiento de Entidades Nombradas} (\textbf{NER}) es el proceso de localizar y clasificar entidades nombradas en un texto dentro de un conjunto de categor\'ias predefinidas de entidades.
Formalmente, dada una secuencia de \emph{tokens} $s = \le w_1, w_2, ..., w_N >$, \textbf{NER} devuelve como salida una lista de tuplas $<I_s, I_e, t>$, una por cada entidad mencionada en s, donde $I_s \in [1,...,N]$ y $I_s \in [1,...,N]$ son el inicio y el fin de los \'indices de la entidad nombrada mencionada; y $t$ es el tipo de la misma dentro de una categor\'ia predefinida~\cite{li2018survey}. 

\textbf{NER} es un paso importante de preprocesamiento para una variedad de downstream applications tales como \emph{Recuperaci\'on de Informaci\'on}, \emph{Preguntas y Respuestas}, \emph{Traducci\'on de m\'aquina}, etc.


\subsection{Enfoque Basado en Reglas}

Los sistemas de \textbf{NER} basados en reglas dependen de \emph{hand-crafted rules}. Las reglas pueden ser dise\~nadas basadas en el dominio espec\'ifico \emph{gazetteers}~\cite{etzioni2005unsupervised},~\cite{sekine2004definition} y en patrones sint\'acticos-l\'exicos~\cite{zhang2013unsupervised}. En el dominio biom\'edico~\cite{hanisch2005prominer} se propuso \emph{ProMiner} el cual utiliza un diccionario de sin\'onimos preprocesado para identificar prote\'inas en texto biom\'edico.

Otros sistemas de \textbf{NER} basados en reglas conocidos son \textbf{LaSIE-II}~\cite{humphreys1998university}, \textbf{NetOwl}~\cite{krupka2005description}, \textbf{Facile}~\cite{black1998facile} y \textbf{SAR}~\cite{aone1998sra}. Todos estos sistemas consisten ensencialmente en \emph{hand-crafted semantic} y reglas sint\'acticas para reconocer entidades. Los sistemas basados en reglas trabajan bien cuando el lexicon es exhaustivo, a su vez con las reglas de dominio espec\'ifico y diccionarios incompletos, alta precisi\'on y bajo recobrdado son comunmente observados en estos sistemas. Adem\'as estos sistemas no pueden ser trasnferidos a otros dominios~\cite{li2018survey}.


\subsection{Enfoques de Aprendizaje no Supervisado}  

Uno de los t\'ipicos enfoques de \textbf{Aprendizaje no Supervisado} es \emph{clustering}~\cite{nadeau2007survey}. Los sistemas de \textbf{NER} basados en \emph{clustering} extraen entidades nombradas de los distintos \emph{clusters} basado en las similiridades del contexto. La idea esencial es que recursos l\'exicos, patrones l\'exicos y estad\'isticas computadas en grandes \emph{corpus} pueden ser utilizadas para inferir entidades nombradas~\cite{li2018survey}. Collins~\cite{collins1999unsupervised} observ\'o que el uso de datos no etiquetados reduce los requerimientos para la supervision a solo 7 simples reglas. Similarmente, el sistema \textbf{KNOWITALL}~\cite{etzioni2005unsupervised} leverage un conjunto de nombres de predicados como entrada y \emph{bootstrap} el proceso de reconocimiento desde un conjunto peque\~no de de patrones gen\'ericos de extracci\'on.

Un sistema no supervisado para la construcci\'on de \emph{gazetteers} y la resoluci\'on de la ambiguedad entre entidades nombradas fue presentado por~\cite{nadeau2006unsupervised}. Este sistema combina \textbf{NER} y la disembiguation de las entidades, basado en simples heur\'isticas que son efectivas a\'un. Enfoques no supervisados para el \textbf{NER} en textos biom\'edicos ha sido presentado por~\cite{zhang2013unsupervised}, donde su modelo depende de terminolog\'ias , estad\'isticas en \emph{corpus}~(la frecuencia de documentos inversa y vectores de contexto) y \emph{shallow syntactic knowledge} (e.g, noun phrase chunking). Los experimentos en dos conjuntos de datos biomedicos demuestran la efectividad y capacidad de generalizaci\'on de su enfoque no supervisado.


\subsection{Enfoque de Aprendizaje Supervisado Basado en Rasgos}

Cuando se aplica \textbf{Aprendizaje Supervisado}, el problema de \textbf{NER} consiste en una tarea de multiclasificaci\'on o etiquetado de secuencias. Donde dados, ejemplos anotados y rasgos dise\~nados para representar cada ejemplo entrenante, los algoritmos de aprendizaje de m\'aquinas son utilizados para aprender el modelo para reconocer patrones similares de datos no vistos~\cite{li2018survey}.

El dise\~no de rasgos es esencial en los sistemas supervisados de \textbf{NER}. La representaci\'on por un vector de rasgos es una abstracci\'on sobre el texto donde una palabra es representada por uno o muchos valores \emph{Booleanos}, \emph{num\'ericos} o nominales~\cite{nadeau2007survey},~\cite{sekine2009named}. Existen rasgos a nivel de palabras (e.g \emph{case}, morfolog\'ia y \emph{part-of-speech tag}~\cite{zhou2002named},~\cite{settles2004biomedical},~\cite{liao2009simple}), lista de \emph{lookup features}(e.g. \emph{Wikipedia} gazetteer y DBpedia gazetteer~\cite{mikheev1999knowledge},~\cite{hoffart2011robust}) y rasgos de documentos y corpus (e.g. sintaxis local  y m\'ultiples ocurrencias~\cite{ravin1997extracting},~\cite{zhu2005espotter},~\cite{ji2016joint},~\cite{krishnan2006effective}).

Utilizando estos rasgos muchos algoritmos de \emph{aprendizaje de m\'aquina} supervisados han sido aplicados en \textbf{NER}. Ejemplo de esto son \emph{Hidden Markov Models} (\textbf{HMM})~\cite{bikel1997nymble},~\cite{bikel1999algorithm}, \emph{Decision Trees}~\cite{quinlan1986induction},~\cite{szarvas2006multilingual}, \emph{Maximum Entropy Models}~\cite{kapur1989maximum},~\cite{borthwick1998nyu},~\cite{bender2003maximum},~\cite{chieu2002named},~\cite{curran2003language}, \emph{Support Vector Machines}(\textbf{SVM}) (REF 69, 78-80) y \emph{Conditional Random Fields}(\textbf{CRF}) (REF 70, 55, 81-84).

\subsection{Enfoque Basado en T\'ecnicas de Aprendizaje Profundo}
En los \'ultimos a\~nos modelos para \textbf{NER} basados en \textbf{Aprendizaje Profundo} se han vuelto dominante. En comparaci\'on con enfoques basados en rasgos, el \textbf{aprendizaje profundo} es capaz de diescubrir rasgos ocultos autom\'aticamente (REF Survey).

Existen 3 ventajas esenciales de aplicar t\'ecnicas de aprendizaje profundo para resolver \textbf{NER}. En primer lugar, \textbf{NER} se beneficia de la aplicaci\'on de transformaciones no lineares, lo cual genera mapeos no lineares de la \emph{entrada} hacia la \emph{salida}. A diferencia de modelos lienares como \textbf{HMM}. En segundo lugar, el aprendizaje profundo ahorra esfuerzo significativo para dise\~nar \textbf{NER} features. Y en tercer lugar, los modelos de aprendizaje profundo para \textbf{NER} puede ser entrenado con un paradigma \emph{end-to-end}, por descenso por gradient. (REF SURVEY)

\subsubsection{Representaci\'on Distribuida de la Entrada}

Una primera opci\'on para la representaci\'on de de una palabra es el \emph{one-hot vector}. En el espacio de los \emph{one-hot vector}, dos palabras tienen completamente dos diferentes representaciones y son ortogonales. Las representaciones distribuidas representan palabras en vectores densos de valores reales con peque\~na dimensi\'on donde cada dimensi\'on representa un rasgo latente. Las representaciones distribuidas capturan propiedades sem\'anticas y sint\'acticas de la palabra.    

Algunos estudios (REF 87-89) utilizan representaciones a nivel de palabras que sin tipicamente pre-entrenadas sobre un largo n\'umero de colecciones de texto a trav\'es de algoritmos no supervisados tales como \emph{continuous bag of words (CBOW)} y \emph{continuous skip-gram models} (REF 90). Estudios recientes como (REF 86 y 91) han mostrado la importancia de los \emph{word embeddings} pre-entrenados. Entre los m\'as comunes se encuentran \emph{Word2Vec} y \emph{GloVe}. En el caso de \textbf{NER} en el dominio de biom\'edico se encuentra \textbf{Bio-NER} (REF 92), donde la represenatci\'on de palabras del mismo es entrenado en la base de datos de \textbf{PubMed} usando un modelo \emph{skip-gram}. Otros trabajos que utilizan  representaciones a nivel de palabra son REF(87, 88, 89, 93, 94, 95, 96, 97).

Otra de las representaciones utilizadas en muchos estudios (REF 98-100) son las basadas en los caracteres de las palabras, la cual se aprende a partir de un modelo de redes neuronales \emph{end-to-end}. La representaci\'on a nivel de caracteres a mostrado ser \'util para explotar informaci\'on por debajo del nivel de la palabra tales como prefijo y sufijos. Adem\'as posee la ventaja que otorga una representaci\'on a palabras que incluso no pertenezcan al vocabulario y compartir informaci\'on a nivel de regularidades de morfemas. Las dos arquitecturas m\'as utilizadas para extraer representaci\'on a nivel de caracteres son las basadas en modelos de \textbf{CNN} (REF 95, 96, 101) y las basadas en modelos de \textbf{RNN} REF(17, 98). En trabajos como (REF 103) se utilizan ambas representaciones para reconocer entidades biomedicas.

Tambi\'en existen representacioes h\'ibridas donde adem\'as de representaciones a nivel de palabras y caracteres, incorporan informaci\'on adicional como los \emph{gazetters} (REF 16) y similaridad l\'exica (REF 107). A\~nadir informaci\'on extra puede mejorar el desempe\~no de \textbf{NER} pero a su vez puede da\~nar la generalizaci\'on de estos sistemas. Un ejemplo de esto es el modelo \emph{BiLSTM-CRF} presentado en (REF 16) donde 4 tipos de rasgos fueron utilizados: \emph{spelling features}, \emph{context features}, \emph{word embeddings} y \emph{gazetters}, los resultados muestran que el uso de rasgos extras como los \emph{gazetters} incrementan la precisi\'on del sistema. El art\'iculo REF(108) presenta un sistema de redes neuronales basado en \emph{CRF} para el reconocimiento y normalizaci\'on de nombres de enfermedades; este sistema utiliza \emph{word embeddings} incluyendo, \emph{POS tags}, \emph{chunking} y rasgos correspondientes a la forma de las palabras (i.e, diccionarios y rasgos morfol\'ogicos). Otros trabajos con representaciones h\'ibridas son (REF 109, 110, 111, 114). Actualmente uno de los modelos de representaci\'on de lenguajes m\'as utilizados es \emph{Bidirectional Encoder Representations from Transformers}(\textbf{BERT}) que utiliza modelos de lenguaje emascarados para permitir el pre-entrenamiento de representaciones bidireccionales. Para un \emph{token} determinado, su representaci\'on es compuesta por su posici\'on correspondiente, segmento y \emph{token embeddings}.


\subsection{Redes Neuronales Convolucionales}

Un ejemplo de un acercamiento a partir de \textbf{CNN} al problema de \textbf{NER} es el presentado en (REF 15) donde una palabra es etiquetada teniendo en consideraci\'on la oraci\'on completa. Cada palabra en la secuencia de entrada se representa a partir de un vector $N-dimensional$ despu\'es de la fase de representaci\'on de la entrada. Luego, una \textbf{CNN} es usada para producir rasgos locales alrededor de cada palabra y el tama\~no de la salida de las capas convolucionales depende en el n\'umero de palabras en la oraci\'on. El vector de rasgos global se construye combinando los vectores de rasgos locales extra\'idos por las capas comvolucionales. La dimensi\'on del vector global de salida es fija en orden de aplicar subsequent affine layers. Dos acercamientos son los m\'as utiizados para extraer rasgos globales: el m\'aximo o el promedio sobre la posici\'on (i.e time step) en la oraci\'on. Finalmente, este vector de rasgos global de dimensi\'on fija es la entrada de el decodificador de etiquetas para computar la distribuci\'on de las puntuaciones para cada una de la etiquetas. Siguiendo el trabajo REF(15) se encuentra el sistema \textbf{Bio-NER} para el reconocimiento de entidades en textos biom\'edicos REF(92). Otros art\'iculos utilizando \textbf{CNN} para el problema de \textbf{NER} son (REF 94, 89).

\subsection{Redes Neuronales Recurrentes}

Las \textbf{RNN} junto sus variantes tales como \emph{Gated Recurrent Unit} (\textbf{GRU}) y \emph{Long Short Term Memory}(\textbf{LSTM}), han demostrado notables logros en la modelaci\'on de datos secuenciales. En particular, las \textbf{RNN} bidireccionales hacen uso eficientemente de informaci\'on pasada (v\'ia \emph{forward states}) y informaci\'on futura (v\'ia \emph{backward states}) para un espec\'ifico time frame (REF 16). Por lo tanto, un \emph{token} codificado por una \textbf{RNN} bidireccional va a contener informaci\'on de toda la oraci\'on. El trabajo de \emph{Huang et al.} REF(16) est\'a entre los primeros en utilizar una arquitectura de \textbf{BiLSTM-CRF} para el etiquetado de secuencias. Siguiendo este trabajo muchos trabajos como REF(17, 18, 87, 88, 93-95, 99, 104, 108, 109) aplican \textbf{BiLSTM} como la arquitectura b\'asica para codificarla informaci\'on de contexto. \emph{Yang et al.} REF(105) utiliz\'o profundas \textbf{GRU} tanto a nivel de caracteres como de palabras para codificar la mprfolog\'ia y la informaci\'on contextual. Trabajos recientes como REF(118, 119) dise\~naron una red neuronal basada en \textbf{LSTM} para el reconocimiento de entidades nombradas nested. Particularmente el trabajo REF(119) propuso un modelo de redes neuronales para identificar entidades nested apilando flat \textbf{NER} layers din\'amicamente hasta que no outer entities are extracted. Cada flat \textbf{NER} layer emplea una \textbf{BiLSTM} para capturar contexto secuencial. El modelo mezcla las salidas de las capas de \textbf{BiLSTM} en el actual flat \textbf{NER} layer para construir nuevas representaciones para la detecci\'on de entidades para que sirvan de entrada la siguiente flat \textbf{NER} layer.

\subsection{Redes Neuronales Recursivas}

Las redes neuronales recursivas son modelos adaptativos no lineales que son capaces de aprender informaci\'on estructurada profunda a partir de explorar una estructura dada en un orden topol\'ogico REF(SURVEY). Las entidades nombradas est\'an altamente relacionadas to linguistic constituents como los sustantivos REF(96). Sin embargo, un acercamiento t\'ipico para el etiquetado de secuencias toma en poca consideraci\'on la estructura de las frases de las oraciones. \emph{Li et al.} REF(96) propuso clasificar cada nodo in a constituency structure for \textbf{NER}. Este modelo calcula recursivamente los vectores ocultos de estado de cada nodo y los clasifica seg\'un los vectores ocultos.

\subsection{Neural Languaje Model}

Los modelos de lenguajes es una familia de modelos describiendo la generaci\'on de secuencias. Dada una secuencia de \emph{tokens} $(t_1, t_2, ..., t_N)$, un forward language model computa la probabilidad de la secuencia a partir de modelar la probabilidad del \emph{token} $t_k$ dado su historia $(t_1,...,t_{k-1})$ (REF 19).

$p(t_1, t_2, ..., t_N) = $

A backward language model es similar a un forward language model, excepto que corre por la secuencia en orden reverso, prediciendo el \emph{token} dado el contexto futuro:

$p(t_1, t_2, ..., t_N) = $

Para los modelos de lenguajes neuronales, la probabilidad del \emph{token} $t_k$ puede ser calculada a partir de la salida de una \textbf{RNN}. En cada posici\'on $k$, se puede obtener dos representaciones dependientes del contexto (forward and backward) y entonces combinarlas como el embedding de lenguaje del modelo final para el \emph{token} $t_k$. Este modelo de lenguaje aumentado ha sido emp\'iricamente verificado como \'util en numerosas tareas de etiquetado REF(19, 102, 120-122). Particularmente en los trabajos REF(121, 122) se utiliza una arquitectura conocida como \textbf{LM-BiLSTM-CRF} donde el modelo de lenguaje y el modelo de etiquetado de secuencia comparten la misma capa a nivel de caracteres en una forma \emph{multi-task}. Los vectores de los \emph{embeddings} a nivel de caracteres, los \emph{word embeddings} pre-entrenados y la representaci\'on del modelo de lenguaje son concatenados y sirven de entrada para las \textbf{LSTM} a nivel de palabra. \emph{Peter et al.} REF(102) propone la representaci\'on \textbf{ELMo} que es computada encima de dos capas de modelos de lenguaje bidireccional con convoluciones de caracteres. Este nuevo tipo de representaci\'on contextualizada profunda de una palabra es capaz de modelar caracter\'isticas complejas del uso de la palabra (sem\'antica y sintaxis), as\'i como el uso de variaciones a trav\'es de distintos contextos lingu\'isticos (polysemy).

\subsection{Deep Transformer}

Modelos neuronales para el etiquetado de secuencias est\'an t\'ipicamente basados en complejas \textbf{CNN} o \textbf{RNN} que consisten de un \emph{encoder} y un \emph{decoder}. Los \emph{Transformers} propuestos por REF(124). Experimentos en varios tasks REF(123-125) muestran que los \emph{Transformers} son superiores en calidad y adem\'as requieren de significativamente menos tiempo para entrenar. Basado en \emph{Transformers} est\'a (REF 126) que proponer \emph{Generative Pretrained Transformer} (\textbf{GPT}) para la tarea del entendimiento de lenguaje. A diferencia de \textbf{GPT} que es una arquitectura de izquierda a derecha, se encuentra \textbf{BERT} (REF 115). La representaci\'on pre-entrenada de \textbf{BERT} puede ser fine-tune con una capa de salida adicional para un amplio rango de tareas, incluyendo \textbf{NER}

\subsection{Arquitecturas de Decodificaci\'on de Etiquetas}

La decodificaci\'on de etiquetas es la etapa final en un modelo de \textbf{NER}. Toma como entrada las representaciones dependientes del contexto y produce una secuencia de etiquetas correspondiente la secuencia de entrada.


Una capa para la decodificaci\'on de etiquetas es la \emph{multi-layer Perceptron + Softmax} donde la tarea del etiquetado de secuencias es tratada como un problema de clasificaci\'on m\'ultiple. La etiqueta para cada palabra es independientemente predicha basado en las representaciones dependientes del contexto sin tener en cuenta sus vecinos. Ejemplos de modelos para \textbf{NER} que usan esta capa para la decodificaci\'on son REF(89, 96, 112, 115).

Otra capa son los \emph{Conditional Random Fields} (\textbf{CRF}) que es un campo aleatorio globalmente condicionado en las observaciones de la secuencia REF(70). Los \textbf{CRF} han sido usado ampliamente en aprendizaje supervisado basado en rasgos. Muchos modelos de \textbf{NER} utilizan \textbf{CRF} como su decodificador de etiquetas, como ejemplo de un \textbf{CRF} encima de una capa \emph{LSTM} es REF(16, 88, 102) y encima de una \textbf{CNN} es REF(15, 89, 92). Sin embargo, \textbf{CRF} no puede hacer un uso completo de la informaci\'on a nivel de segmentos porque las propiedades internas de los segmentos no pueden ser completamente codificadas con representaciones a nivel de palabra (REF Survey). \emph{Zhuo et al.} REF(128) propuso el \emph{gated recursive semi-markov CRF}, el cual directamente modela los segmentos en vez de palabras y automaticamente extrae rasgos a nivel de segmentos a trav\'es de una \emph{gated recursive convolutional neural network}. Recientemente \emph{Ye and Ling} REF(129) propusieron un h\'ibrido \emph{semi-Markov CRF} para el etiquetado de secuencias a partir de redes neuronales. Este acercamiento adopta segmentos en vez de palabras como su unidad b\'asica para la extracci\'on de rasgos y modelado de transiciones (REF Survey). Las etiquetas a nivel de palabras son utilizadas para derivar puntuaciones de segmentos. As\'i que este acercamiento es capas de subir el nivel tanto la informaci\'on a nivel de palabra como a nivel de segmento para cada c\'alculo de la puntuaci\'on de un segmento.

Algunos estudios como REF(86-88, 94, 130) han explorado \textbf{RNN} para la decodificaci\'on de etiquetas. \emph{Shen et al.} REF(86) report\'o que las \textbf{RNN} superan a los \textbf{CRF} y son m\'as r\'apidas de entrenar cuando el n\'umero de tipos de entidades es grande.

\emph{Pointer Networks} utilizan \textbf{RNNs} para aprender la probabilidad condicional de una secuencia de salida con elementos que son \emph{tokens} discretos correspondientes a las posiciones en la secuencia de entrada REF(131). Representan diccionarios de tama\~nos variables usando la distribuci\'on de probabilidad \emph{softmax} como un puntero. \emph{Zhai et al.} REF(93) aplic\'o por primera vez \emph{Pointer Networks} para producir secuencia de etiquetas. 


\subsection{T\'ecnicas de Deep Learning para NER}
En las \'ultimas secciones se ha hecho un resumen de las t\'ipicas arquitecturas para enfrentar el problema de \textbf{NER}. En esta secci\'on presentamos t\'ecnicas de \textbf{Deep Learning} recientemente aplicadas a \textbf{NER}. Entre estas se incluyen \emph{deep multi-task learning}, \emph{deep transfer learning}, \emph{deep active learning}, \emph{deep reinforcement learning}, \emph{deep adversarial learning}, y \emph{neural attention}.

\subsubsection{Deep Multi-Task Learning}

\emph{Multi-task learning} es un acercamiento que aprende un conjunto de tareas juntas REF(143). Si se consideran las relaciones entre las diferentes tareas, se espera que los algoritmos de \emph{multi-task learning} consigan mejores resultados que aquellos que aprenden una tarea individualmente REF(SURVEY).

Trabajos como REF(15) han entrenado modelos para conjuntamente enfrentar las tareas de \textbf{POS}, \textbf{Chunk}, \textbf{NER} y \textbf{SRL}. El trabajo de \emph{Yang et al.} REF(105) propuso un modelo conjunto \emph{multi-task}, para aprender regularidades espec\'ificas del lenguaje, entrenando conjuntamente en las tareas de \textbf{POS}, \textbf{NER}, \textbf{Chunk}. La idea del \emph{multi-task learning} ha sido aplicada adem\'as para entrenar modelos conjuntos para \textbf{NER} y a su vez la extracci\'on y clasificaci\'on de relaciones REF(88, 94) o adem\'as modelar \textbf{NER} como dos subtareas relacionadas, la segmentaci\'on de entidades y la predicci\'on de las categor\'ias  de las entidades REF(110, 144). En el dominio biom\'edico, debido a las diferencias en los distintos conjuntos de datos, la tarea de \textbf{NER} en cada conjunto de datos es considerada una tarea en una configuraci\'on \emph{multi-task} REF(145, 146). La principal suposici\'on es que los diferentes conjuntos de datos comparten la misma informaci\'on a nivel de caracteres y de palabras, entonces \emph{multi-taks learning} es aplicado para hacer un uso m\'as eficiente de los datos and to encourage el modelo  a aprender representaciones m\'as generalizadas.


\subsubsection{Deep Transfer Learning}

\emph{Transfer Learning} apunta a lograr un mejor desempe\~no de una tarea de aprendizaje de m\'aquina en un dominio espec\'ifico tomando ventaja del conocimiento aprendido del dominio fuente REF(147). En \textbf{NLP}, \emph{trasnfer learning} es tambi\'en conocido como adaptaci\'on de dominio. En las tareas de \textbf{NER} el acercamiento tradicional es a trav\'es de los algoritmos de \emph{bootstrapping} REF(148, 149). Recientemente, nuevos acercamientos como REF(150,151) han propuesto usar redes neruronales profundas for accross-domain \textbf{NER}.
En las configuraciones de \emph{transfer learning} diferentres modelos neuronales comunmente comparten diferentes partes de los par\'ametros del modelo entre la tarea fuente y la tarea objetivo. \emph{Yang et al.} REF(153) fue el primero en investigar la tranferibilidad de las diferentes capas de representaci\'on, entonces presentaron 3 diferentes arquitecturas de compartir par\'ametros para escenarios de \emph{cross-domain}, \emph{cross-lingual} y  \emph{cross-application}. En particular si dos tareas tienen conjuntos de etiquetas mapeables, entonces hay una capa de \textbf{CRF} compartida, en otro caso cada tarea tiene su propia capa de \textbf{CRF}. Otros trabajos de \emph{trasnfer learning} en \textbf{NER} son (154-157, 151, 146).

\subsubsection{Deep Active Learning}

La idea esencia detr\'as de \emph{deep active learning} es que un algoritmo de aprendizaje de m\'aquina pueda desempe\~narse mejor con una cantidad substancial menor de datos de entrenamiento, si se permite elegir los datos con los que entrenar\'a REF(158). Aprendizaje profundo requiere una gran cantidad de datos de entrenamiento que es costoso de obtener. Por lo tanto, combinando aprendizaje profundo con \emph{active learning} se espera que se reduzca el esfuerzo de anotaci\'on de los datos.

Entrenamiento con \emph{active learning} procede en m\'ultiples rondas. Sin embargo, los esquemas tradicionales de \emph{active learning} son costosos para aprendizaje profundo, porque despu\'es de cada ronda requiere un reentrenamiento completo del clasificador con nuevos datos anotados. Precisamente porque el reentrenamiento desde el inicio no es pr\'actico para aprendizaje profundo \emph{Shen et al.} REF(86) propuso un entrenamiento incremental para \textbf{NER} con cada \emph{batch} de nuevas etiquetas. La idea, es mezclar nuevos ejemplos anotados con algunos ya existentes, y actualizar los pesos la red neuronal para un n\'umero peque\~no de \emph{epochs}, antes de consultar por etiquetas en una nueva ronda. Espec\'ificamente, al inicio de cada ronda, el algoritmo de \emph{active learning} elige oraciones para ser anotadas,
to the predefined budget. Los par\'ametros del modelo son actualizados por el entrenamiento en el conjunto de datos aumentado, despu\'es de recibir las anotaciones seleccionadas.

\subsubsection{Deep Reinforcement Leaarning}

\emph{Reinforcement Learning} es una rama del aprendizaje de m\'aquinas inspirada por la psicolog\'ia del comportamiento, que tiene que ver con c\'omo agentes de software toman acci\'on en el ambiente con el objetivo de maximizar alguna recompensa acumulativa  REF(161, 162). La idea es que el agente aprender\'a a partir de la interacci\'on con en el ambiente y recibiendo recompensas por realizar acciones. Especifiamente el problema del \emph{reinforcement learning} puede ser formulado de la siguiente forma REF(163): el ambiente es modelado como una m\'aquina de estado estoc\'astica finita con entradas (acciones del agente) y salidas (observaciones y recompensa del agente). Esto consiste en 3 componentes claves: (i) la funci\'on de transici\'on de estados, (ii) funci\'on de observaciones (o sea, salida) y (iii) la funci\'on de recompensa. El agente es tambi\'en modelado como una m\'aquina de estado estoc\'astica finita con entradas (observaciones y recompensas del ambiente) y salidas (acciones en ell ambiente). Esto consiste en dos componentes: (i) una funci\'on de transici\'on de estado, y (ii) una funci\'on de salida. La meta final del agente es aprender una buena gunci\'on de actualizaci\'on de estado intentando maximixar las recompensas acumuladas.

\emph{Narasimhan et al.} REF(164) model\'o la tarea de extracci\'on de informaci\'on como un proceso de decisi\'on de \emph{Markov} \textbf{MDP}, el cual din\'amicamente incorpora predicci\'on de entidades y provee de flexibilidad para elegir las siguiente consulta de b\'usqueda de un conjunto de alternativas autom\'aticamente generado.

\subsection{Deep Adversarial Learning}

\emph{Adversarial Learning} es el proceso de explic\'itamente entrenar un modelo en ejemplos adversariales. El prop\'osito es hacer el modelo m\'as robusto contra ataques o reducir sus test error on clean inputs. \emph{Adversarial networks} aprenden a generar a partir de una distribuci\'on de entrenamiento a trav\'es de un juego de dos jugadores: una red genera candidatos (\emph{generative network}) y la otra los eval\'ua (\emph{discriminative network}). T\'ipicamente, la red generativa aprende a mapear de un espacio latente a una distribuci\'on particular de los datos de inter\'es, mientras que la red discriminativa discrimina entre los candidatos generados por el generador e instancias de la distribuci\'on de datos del mundo real REF(167).

\emph{Dual adversarial transfer network} ()\textbf{DATNet}), propuesto en REF(168) apunta a lidiar con el problema de los bajos recursos en \textbf{NER}. Los autores preparan una muestra adversarial a\~nadiendole a la muestra original una perturbaci\'on acotada por una peque\~na norma $\epsilon$ para maximizar la funci\'on d p\'erdida como sigue:

%$ηx = arg max
%η:kηk2≤ǫ
%l(Θ; x + η) (3)$

%donde $\theta$ es el conjunto actual de par\'ametros del model, $\epsilon$ puede ser determinado en el conjunto de validaci\'on. Un ejemplo adversarial es construido por $x_adv = x + η_x$ El clasificador es entrenado en la mezcla de los ejemplos originales y los adversariales para mejorar la generalizaci\'on.


\subsection{Neural Attention}

El mecanismo de \emph{attention} en una red neuronal is loosely based en el mecanismo de atenci\'on virtual del humano REF(169). El mecanismo de \emph{neural attention} permite a las redes neuronales la habilidad de enfocarse en un subconjunto de sus entradas. Aplicando mecanismos de atenci\'on, un modelo de \textbf{NER} puede capturar los elementos m\'as informativos de las entradas.

Existen muchas formas de aplicar el mec\'anismo de atenci\'on en las tareas de \textbf{NER}. \emph{Rei et al.} REF(104), aplic\'o el mecanismo de atenci\'on para din\'amicamente decidir cu\'anta informaci\'on utilizar de una componente a nivel de caracteres o palabras en un modelo de \textbf{NER} \emph{end-to-end}. \emph{Zukov-Gregoric et al.} REF(170) explor\'o el mecanismo de \emph{self-attention} en \textbf{NER}, donde los pesos son dependientes de una sola secuencia 

\section{Extracción de Relaciones}

\section{Enfoque Conjunto}
%===================================================================================

